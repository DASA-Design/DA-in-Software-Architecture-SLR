@inproceedings{arcaini_modeling_2015,
  title      = {Modeling and {{Analyzing MAPE-K Feedback Loops}} for {{Self-Adaptation}}},
  booktitle  = {2015 {{IEEE}}/{{ACM}} 10th {{International Symposium}} on {{Software Engineering}} for {{Adaptive}} and {{Self-Managing Systems}}},
  author     = {Arcaini, Paolo and Riccobene, Elvinia and Scandurra, Patrizia},
  date       = {2015-05},
  year       = {2015},
  publisher  = {IEEE},
  address    = {Florence, Italy},
  pages      = {13--23},
  issn       = {2157-2321},
  doi        = {10.1109/SEAMS.2015.10},
  abstract   = {The MAPE-K (Monitor-Analyze-Plan-Execute over a shared Knowledge) feedback loop is the most influential reference control model for autonomic and self-adaptive systems. This paper presents a conceptual and methodological framework for formal modeling, validating, and verifying distributed self-adaptive systems. We show how MAPE-K loops for self adaptation can be naturally specified in an abstract stateful language like Abstract State Machines. In particular, we exploit the concept of multi-agent Abstract State Machines to specify decentralized adaptation control by using MAPE computations. We support techniques for validating and verifying adaptation scenarios, and getting feedback of the correctness of the adaptation logic as implemented by the MAPE-K loops. In particular, a verification technique based on meta-properties is proposed to allow discovering unwanted interferences between MAPE-K loops at the early stages of the system design. As a proof-of concepts, we model and analyze a traffic monitoring system.},
  eventtitle = {2015 {{IEEE}}/{{ACM}} 10th {{International Symposium}} on {{Software Engineering}} for {{Adaptive}} and {{Self-Managing Systems}}},
  keywords   = {Abstract State Machines,Adaptation models,Analytical models,Cameras,Computational modeling,formal modeling,MAPE-K,Monitoring,Organizations,self-adaptation,Unified modeling language,validation & verification}
}

@article{arcelli_exploiting_2020,
  title      = {Exploiting {{Queuing Networks}} to {{Model}} and {{Assess}} the {{Performance}} of {{Self-Adaptive Software Systems}}: {{A Survey}}},
  shorttitle = {Exploiting {{Queuing Networks}} to {{Model}} and {{Assess}} the {{Performance}} of {{Self-Adaptive Software Systems}}},
  author     = {Arcelli, Davide},
  year       = {2020},
  month      = jan,
  journal    = {Procedia Computer Science},
  series     = {The 11th {{International Conference}} on {{Ambient Systems}}, {{Networks}} and {{Technologies}} ({{ANT}}) / {{The}} 3rd {{International Conference}} on {{Emerging Data}} and {{Industry}} 4.0 ({{EDI40}}) / {{Affiliated Workshops}}},
  volume     = {170},
  pages      = {498--505},
  issn       = {1877-0509},
  doi        = {10.1016/j.procs.2020.03.108},
  urldate    = {2024-09-17},
  abstract   = {Self-adaptation has emerged as a primary concern in the context of modern software systems, due to the high dynamicity of the environments where they operate, which implies the need for such systems to properly face significant degrees of uncertainty. To this aim, much work has been done, mainly by coupling autonomic managers to the managed subsystem which perceives and affects the environment through its sensors and actuators, respectively. Such coupling often results into MAPE-K feedback loop(s), i.e. a Knowledge (K)-based architectural model that divides the adaptation process into four activities, namely Monitor (M), Analyze (A), Plan (P) and Execute (E). Performance modeling notations, analysis methods and tools, have been exploited and coupled to other kinds of techniques (e.g. control theory, machine learning) for modeling and assessing the performance of autonomic managers, possibly aimed at supporting the identification of more convenient architectural alternatives. Since moving in such a big arena is not trivial and it is easy to be overwhelmed, in this literature survey, we focus on a particular performance modeling paradigm, namely Queuing Networks, with the aim of clarifying the state-of-art in exploiting such a notation to model and assess performance of Self-Adaptive Software Systems. We conclude by bringing out some research opportunities that may be worth exploring in the near future.},
  keywords   = {Autonomous Systems,Performance Engineering,Queuing Networks,Self-Adaptive Software Systems,Software Architectures}
}

@inproceedings{ardagna_rethinking_2008,
  title     = {Rethinking the {{Use}} of {{Models}} in {{Software Architecture}}},
  booktitle = {Quality of {{Software Architectures}}. {{Models}} and {{Architectures}}},
  author    = {Ardagna, Danilo and Ghezzi, Carlo and Mirandola, Raffaela},
  editor    = {Becker, Steffen and Plasil, Frantisek and Reussner, Ralf},
  year      = {2008},
  pages     = {1--27},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  doi       = {10.1007/978-3-540-87879-7_1},
  abstract  = {Models play a central role in software engineering. They may be used to reason about requirements, to identify possible missing parts or conflicts. They may be used at design time to analyze the effects and trade-offs of different architectural choices before starting an implementation, anticipating the discovery of possible defects that might be uncovered at later stages, when they might be difficult or very expensive to remove. They may also be used at run time to support continuous monitoring of compliance of the running system with respect to the desired model. This paper focuses on models that support reasoning about non-functional system properties --- namely, performance and reliability. It provides a taxonomy, which tries to capture the main facets that are needed to understand, choose, and use models appropriately in the various phases of software development and operation. The paper also focuses on the roundtrip from models to reality and back. The forward path is followed in model-driven development. The backward path is instead meant to enable model calibration, with the goal of building adequate abstractions, which reflect reality and its properties in a faithful manner. Calibration may be required because of flaws in the initial model or in the process that derived the implementation, or because of changes that occurred in the environment or in the requirements. This leads to the idea that models should continue to live at run time, on-line with the running implementation. Calibrated models may drive the necessary dynamic changes that may support self-adaptation of the implemented system.},
  isbn      = {978-3-540-87879-7},
  langid    = {english},
  keywords  = {Linear Parameter Vary,Model Check,Probabilistic Model Check,Queue Network Model,Request Arrival Rate}
}

@article{balsamo_applying_2015,
  title    = {Applying {{BCMP}} Multi-Class Queueing Networks for the Performance Evaluation of Hierarchical and Modular Software Systems},
  author   = {Balsamo, Simonetta and Rossi, Gian and Marin, Andrea},
  year     = {2015},
  month    = jan,
  journal  = {International Journal of Computer Aided Engineering and Technology},
  volume   = {7},
  pages    = {145},
  doi      = {10.1504/IJCAET.2015.068328},
  abstract = {Queueing networks with multiple classes of customers play a fundamental role for evaluating the performance of both software and hardware architectures. The main strength of product-form models, in particular of BCMP queueing networks, is that they combine a flexible formalism with efficient analysis techniques and solution algorithms. In this paper we provide an algorithm that starting from a high-level description of a system, and from the definition of its components in terms of interacting sub-systems, computes a multiple-class and multiple-chain BCMP queueing network. We believe that the strength of this approach is twofold. First, the modeller deals with simplified models, which are defined in a modular and hierarchical way. Hence, we can carry on sensitivity analysis that may easily include structural changes (and not only on the time parameters). Second, maintaining the product-form property allows one to derive the average system performance indices very efficiently. The paper also discusses the application of the algorithm for the performance evaluation of websites with modular architectures, such as those based on content management systems.},
  keywords = {BCMP networks,content management systems,hierarchical software,modelling,modular software,multi-class queueing,performance evaluation,product-form solutions,queueing networks,software engineering}
}

@inproceedings{balsamo_performance_2005,
  title     = {Performance Evaluation of {{UML}} Software Architectures with Multiclass {{Queueing Network}} Models},
  booktitle = {Proceedings of the 5th International Workshop on {{Software}} and Performance},
  author    = {Balsamo, Simonetta and Marzolla, Moreno},
  year      = {2005},
  month     = jul,
  series    = {{{WOSP}} '05},
  pages     = {37--42},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  doi       = {10.1145/1071021.1071025},
  urldate   = {2024-09-16},
  abstract  = {Software performance based on performance models can be applied at early phases of the software development cycle to characterize the quantitative behavior of software systems. We propose an approach based on queueing networks models for performance prediction of software systems at the software architecture level, specified by UML. Starting from annotated UML Use Case, Activity and Deployment diagrams we derive a performance models based on multichain and multiclass Queueing Networks (QN). The UML model is annotated according to the UML Profile for Schedulability, Performance and Time Specification. The proposed algorithm translates the annotated UML specification into QN performance models, which can then be analyzed using standard solution techniques. Performance results are reported back at the software architecture level in the UML diagrams. As our approach can be fully automated and uses standard UML annotations, it can be integrated with other performance modeling approaches. Specifically, we discuss how this QN-based approach can be integrated with an existing simulation-based performance modeling tool.},
  isbn      = {978-1-59593-087-3}
}

@article{balsamo_review_2003,
  title    = {A Review on Queueing Network Models with Finite Capacity Queues for Software Architectures Performance Prediction},
  author   = {Balsamo, Simonetta and De Nitto Person{\`e}, Vittoria and Inverardi, Paola},
  year     = {2003},
  month    = feb,
  journal  = {Performance Evaluation},
  series   = {Queueing {{Networks}} with {{Blocking}}},
  volume   = {51},
  number   = {2},
  pages    = {269--288},
  issn     = {0166-5316},
  doi      = {10.1016/S0166-5316(02)00099-8},
  urldate  = {2024-09-17},
  abstract = {A review is carried out on how queueing network models with blocking have been applied so far into the performance evaluation and prediction of Software Architectures (SA). Queueing network models with finite capacity queues and blocking have recently been introduced and applied as more realistic models of systems with finite capacity resources and population constraints. Queueing network models have been often adopted as models for the evaluation of software performance. Starting from our own experience, we observe the need of a more accurate definition of the performance models of SA to capture some features of the communication systems. We consider queueing networks with finite capacity and blocking after service (BAS) to represent some synchronization constraints that cannot be easily modeled with queueing network models with infinite capacity queues. We investigate the use of queueing networks with blocking as performance models of SA with concurrent components and synchronous communication. Queueing theoretic analysis is used to solve the queueing network model and study the synchronous communication and performance of concurrent software components. Our experience is supported by other approaches that also propose the use of queueing networks with blocking. Directions for future research work in the field are included.},
  keywords = {Blocking after service,Modelling,Queueing network,Software architectures}
}

@book{bischof_computational_2007,
  title      = {Computational {{Force}}: {{A Unifying Concept}} for {{Scalability Analysis}}},
  shorttitle = {Parallel Computing},
  author     = {Numrich, Robert},
  editor     = {Bischof, Christian and {John von Neumann-Institut f{\"u}r Computing}},
  year       = {2007},
  series     = {{{NIC}} Series},
  number     = {38},
  publisher  = {NIC-Secretariat, Research Centre J{\"u}lich},
  address    = {J{\"u}lich},
  isbn       = {978-3-9810843-4-4 978-1-58603-796-3},
  langid     = {english}
}

@article{bonabeau_agent-based_2002,
  title      = {Agent-Based Modeling: {{Methods}} and Techniques for Simulating Human Systems},
  shorttitle = {Agent-Based Modeling},
  author     = {Bonabeau, Eric},
  year       = {2002},
  month      = may,
  journal    = {Proceedings of the National Academy of Sciences},
  volume     = {99},
  number     = {suppl 3},
  pages      = {7280--7287},
  publisher  = {National Academy of Sciences},
  issn       = {0027-8424, 1091-6490},
  doi        = {10.1073/pnas.082080899},
  urldate    = {2022-02-28},
  abstract   = {Agent-based modeling is a powerful simulation modeling technique that has seen a number of applications in the last few years, including applications to real-world business problems. After the basic principles of agent-based simulation are briefly introduced, its four areas of application are discussed by using real-world applications: flow simulation, organizational simulation, market simulation, and diffusion simulation. For each category, one or several business applications are described and analyzed.},
  chapter    = {Colloquium Paper},
  copyright  = {Copyright {\copyright} 2002, The National Academy of Sciences},
  langid     = {english},
  pmid       = {12011407}
}

@incollection{carmichael_fundamentals_2019,
  title     = {The {{Fundamentals}} of {{Complex Adaptive Systems}}},
  booktitle = {Complex {{Adaptive Systems}}: {{Views}} from the {{Physical}}, {{Natural}}, and {{Social Sciences}}},
  author    = {Carmichael, Ted and Had{\v z}ikadi{\'c}, Mirsad},
  editor    = {Carmichael, Ted and Collins, Andrew J. and Had{\v z}ikadi{\'c}, Mirsad},
  year      = {2019},
  series    = {Understanding {{Complex Systems}}},
  pages     = {1--16},
  publisher = {Springer International Publishing},
  address   = {Cham},
  doi       = {10.1007/978-3-030-20309-2_1},
  urldate   = {2021-09-20},
  abstract  = {Complex Adaptive Systems (CAS) is a framework for studying, explaining, and understanding systems of agents that collectively combine to form emergent, global level properties. These agents can be nearly anything, from ants or bees, to brain cells, to water particles in a weather pattern, to groups of cars or people in a city or town. These agents produce emergent patterns via correlated feedbacks throughout the system, feedbacks that create and fortify a basin of attraction: a persistent pattern of behavior that itself is outside of equilibrium. There is also an ever-growing understanding that similar features in complex systems across a diversity of domains may indicate similar fundamental principles at work, and as such there is often utility in using the key features of one system to gain insight into the workings of seemingly distinct fields. Here we also include a brief review of multiple models that attempt to do exactly this, including some of our previous work. Though there is not complete agreement on all aspects and definitions in this field, this introduction also summarizes our understanding of what defines a CAS, including the concepts of complexity, agents, adaptation, feedbacks, emergence, and self-organization; and places this definition and its key features in a historical context. Finally we briefly discuss two of the common biases often found that the tools of CAS can help counteract: the hierarchical bias, assuming a strong top-down organization; and the complexity bias, the tendency to assign complicated features to agents that turn out to be quite simple.},
  isbn      = {978-3-030-20309-2},
  langid    = {english}
}

@book{cervantes_designing_2016,
  title      = {Designing {{Software Architectures}}: {{A Practical Approach}}},
  shorttitle = {Designing {{Software Architectures}}},
  author     = {Cervantes, Humberto and Kazman, Rick},
  year       = {2016},
  month      = may,
  edition    = {1 edition},
  publisher  = {Addison-Wesley Professional},
  address    = {Boston},
  abstract   = {Designing Software Architectures  will teach you how to design any software architecture in a systematic, predictable, repeatable, and cost-effective way.    This book introduces a practical methodology for architecture design that any professional software engineer can use, provides structured methods supported by reusable chunks of design knowledge, and includes rich case studies that demonstrate how to use the methods. ~ Using realistic examples, you'll master the powerful new version of the proven Attribute-Driven Design (ADD) 3.0 method and will learn how to use it to address key drivers, including quality attributes, such as modifiability, usability, and availability, along with functional requirements and architectural concerns. ~ Drawing on their extensive experience, Humberto Cervantes and Rick Kazman guide you through crafting practical designs that support the full software life cycle, from requirements to maintenance and evolution. You'll learn how to successfully integrate design in your organizational context, and how to design systems that will be built with agile methods.    Comprehensive coverage includes    Understanding what architecture design involves, and where it fits in the full software development life cycle Mastering core design concepts, principles, and processes Understanding how to perform the steps of the ADD method Scaling design and analysis up or down, including design for pre-sale processes or lightweight architecture reviews Recognizing and optimizing critical relationships between analysis and design Utilizing proven, reusable design primitives and adapting them to specific problems and contexts Solving design problems in new domains, such as cloud, mobile, or big data},
  isbn       = {978-0-13-439078-9},
  langid     = {english}
}

@article{cheng_optimization_2014,
  title    = {Optimization of Rhombic Drive Mechanism Used in Beta-Type {{Stirling}} Engine Based on Dimensionless Analysis},
  author   = {Cheng, Chin-Hsiang and Yang, Hang-Suin},
  year     = {2014},
  month    = jan,
  journal  = {Energy},
  volume   = {64},
  pages    = {970--978},
  issn     = {0360-5442},
  doi      = {10.1016/j.energy.2013.11.054},
  urldate  = {2019-08-13},
  abstract = {In the present study, optimization of rhombic drive mechanism used in a beta-type Stirling engine is performed based on a dimensionless theoretical model toward maximization of shaft work output. Displacements of the piston and the displacer with the rhombic drive mechanism and variations of volumes and pressure in the chambers of the engine are firstly expressed in dimensionless form. Secondly, Schmidt analysis is incorporated with Senft's shaft work theory to build a dimensionless thermodynamic model, which is employed to yield the dimensionless shaft work. The dimensionless model is verified with experimental data. It is found that the relative error between the experimental and the theoretical data in dimensionless shaft work is lower than 5.2\%. This model is also employed to investigate the effects of the influential geometric parameters on the shaft work, and the optimization of these parameters is attempted. Eventually, design charts that help design the optimal geometry of the rhombic drive mechanism are presented in this report.},
  keywords = {Design charts,Optimization,Rhombic drive,Stirling engine}
}

@article{colakoglu_software_2021,
  title      = {Software {{Product Quality Metrics}}: {{A Systematic Mapping Study}}},
  shorttitle = {Software {{Product Quality Metrics}}},
  author     = {Colakoglu, Fatima Nur and Yazici, Ali and Mishra, Alok},
  year       = {2021},
  journal    = {IEEE Access},
  volume     = {9},
  pages      = {44647--44670},
  issn       = {2169-3536},
  doi        = {10.1109/ACCESS.2021.3054730},
  urldate    = {2024-11-14},
  abstract   = {In the current competitive world, producing quality products has become a prominent factor to succeed in business. In this respect, defining and following the software product quality metrics (SPQM) to detect the current quality situation and continuous improvement of systems have gained tremendous importance. Therefore, it is necessary to review the present studies in this area to allow for the analysis of the situation at hand, as well as to enable us to make predictions regarding the future research areas. The present research aims to analyze the active research areas and trends on this topic appearing in the literature during the last decade. A Systematic Mapping (SM) study was carried out on 70 articles and conference papers published between 2009 and 2019 on SPQM as indicated in their titles and abstract. The result is presented through graphics, explanations, and the mind mapping method. The outputs include the trend map between the years 2009 and 2019, knowledge about this area and measurement tools, issues determined to be open to development in this area, and conformity between conference papers, articles and internationally valid quality models. This study may serve as a foundation for future studies that aim to contribute to the development in this crucial field. Future SM studies might focus on this subject for measuring the quality of network performance and new technologies such as Artificial Intelligence (AI), Internet of things (IoT), Cloud of Things (CoT), Machine Learning, and Robotics.},
  keywords   = {ISO Standards,Market research,Measurement,metrics,Object oriented modeling,Product design,Quality assessment,software product quality,Software quality,systematic mapping}
}

@article{denning_operational_1978,
  title   = {The {{Operational Analysis}} of {{Queueing Network Models}}},
  author  = {Denning, Peter J. and Buzen, Jeffrey P.},
  year    = {1978},
  month   = sep,
  journal = {ACM Comput. Surv.},
  volume  = {10},
  number  = {3},
  pages   = {225--261},
  issn    = {0360-0300},
  doi     = {10.1145/356733.356735},
  urldate = {2024-09-18}
}

@article{dumka_implementation_2022,
  title    = {Implementation of {{Buckingham}}'s {{Pi}} Theorem Using {{Python}}},
  author   = {Dumka, Pankaj and Chauhan, Rishika and Singh, Ayush and Singh, Gaurav and Mishra, Dhananjay},
  year     = {2022},
  month    = nov,
  journal  = {Advances in Engineering Software},
  volume   = {173},
  pages    = {103232},
  issn     = {0965-9978},
  doi      = {10.1016/j.advengsoft.2022.103232},
  urldate  = {2023-07-18},
  abstract = {Buckingham's Pi theorem plays an important role in engineering, applied mathematics, and physics for dimensional analysis. From the given variables, it will be utilised to evaluate the set of dimensionless parameters. It indicates that the validity of the physical law is independent of the specific unit system, and it can be expressed as an identity incorporating only dimensionless variables associated with the law. A python-based function has been developed and reported in this manuscript, which can be utilised to evaluate Pi terms (commonly called {$\pi$} terms) for any fluid flow problem. Smaller moderation in the written function can make it capable of solving any fundamental dimensions. Different fluid mechanics problems are utilised to test and validate the reported function, five of which are presented in this manuscript along with code. Obtained results are in good agreement with the theoretically obtained results.},
  langid   = {english},
  keywords = {Buckingham's Pi theorem,Dimensional analysis,Fluid mechanics,Physical similarity analysis,Python programming}
}

@inproceedings{el-ansary_efficient_2003,
  title     = {Efficient {{Broadcast}} in {{Structured P2P Networks}}},
  booktitle = {Peer-to-{{Peer Systems II}}},
  author    = {{El-Ansary}, Sameh and Alima, Luc Onana and Brand, Per and Haridi, Seif},
  editor    = {Kaashoek, M. Frans and Stoica, Ion},
  year      = {2003},
  pages     = {304--314},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  doi       = {10.1007/978-3-540-45172-3_28},
  abstract  = {In this position paper, we present an efficient algorithm for performing a broadcast operation with minimal cost in structured DHT-based P2P networks. In a system of N nodes, a broadcast message originating at an arbitrary node reaches all other nodes after exactly N\,-\,1 messages. We emphasize the perception of a class of DHT systems as a form of distributed k-ary search and we take advantage of that perception in constructing a spanning tree that is utilized for efficient broadcasting. We consider broadcasting as a basic service that adds to existing DHTs the ability to search using arbitrary queries as well as dissiminate/collect global information.},
  isbn      = {978-3-540-45172-3},
  langid    = {english}
}

@article{elhabbash_self-awareness_2019,
  title        = {Self-Awareness in {{Software Engineering}}: {{A Systematic Literature Review}}},
  shorttitle   = {Self-Awareness in {{Software Engineering}}},
  author       = {Elhabbash, Abdessalam and Salama, Maria and Bahsoon, Rami and Tino, Peter},
  date         = {2019-10-17},
  year         = {2019},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  journaltitle = {ACM Transactions on Autonomous and Adaptive Systems},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  volume       = {14},
  number       = {2},
  pages        = {5:1--5:42},
  issn         = {1556-4665},
  doi          = {10.1145/3347269},
  url          = {http://doi.org/10.1145/3347269},
  urldate      = {2020-09-13},
  abstract     = {Background: Self-awareness has been recently receiving attention in computing systems for enriching autonomous software systems operating in dynamic environments. Objective: We aim to investigate the adoption of computational self-awareness concepts in autonomic software systems and motivate future research directions on self-awareness and related problems. Method: We conducted a systemic literature review to compile the studies related to the adoption of self-awareness in software engineering and explore how self-awareness is engineered and incorporated in software systems. From 865 studies, 74 studies have been selected as primary studies. We have analysed the studies from multiple perspectives, such as motivation, inspiration, and engineering approaches, among others. Results: Results have shown that self-awareness has been used to enable self-adaptation in systems that exhibit uncertain and dynamic behaviour. Though there have been recent attempts to define and engineer self-awareness in software engineering, there is no consensus on the definition of self-awareness. Also, the distinction between self-aware and self-adaptive systems has not been systematically treated. Conclusions: Our survey reveals that self-awareness for software systems is still a formative field and that there is growing attention to incorporate self-awareness for better reasoning about the adaptation decision in autonomic systems. Many pending issues and open problems outline possible research directions.},
  keywords     = {Adaptation processes,research challenges,self-adaptive software,self-aware software,self-properties,software architecture,survey,systematic literature review}
}

@book{ferguson_internal_2000,
  title      = {Internal {{Combustion Engines}}: {{Applied Thermosciences}}},
  shorttitle = {Internal {{Combustion Engines}}},
  author     = {Ferguson, Colin R. and Kirkpatrick, Allan T.},
  year       = {2000},
  month      = nov,
  edition    = {2nd Edition},
  publisher  = {Wiley},
  address    = {New York},
  abstract   = {This book presents a modern approach to the study of internal combustion engines! Building upon the foundation of the first edition, the book has been completely revised, with each chapter reorganized and updated. The purpose of the book is to apply the principles of thermodynamics, fluid mechanics, and heat transfer to the analysis of internal combustion engines. The text also features modern web-based computational methods.},
  isbn       = {978-0-471-35617-2},
  langid     = {english}
}

@article{gheibi_applying_2021,
  title        = {Applying {{Machine Learning}} in {{Self-adaptive Systems}}: {{A Systematic Literature Review}}},
  shorttitle   = {Applying {{Machine Learning}} in {{Self-adaptive Systems}}},
  author       = {Gheibi, Omid and Weyns, Danny and Quin, Federico},
  date         = {2021-08-18},
  year         = {2021},
  journal      = {ACM Transactions on Autonomous and Adaptive Systems},
  journaltitle = {ACM Transactions on Autonomous and Adaptive Systems},
  shortjournal = {ACM Trans. Auton. Adapt. Syst.},
  volume       = {15},
  number       = {3},
  pages        = {9:1--9:37},
  issn         = {1556-4665},
  doi          = {10.1145/3469440},
  url          = {http://doi.org/10.1145/3469440},
  urldate      = {2021-09-20},
  abstract     = {Recently, we have been witnessing a rapid increase in the use of machine learning techniques in self-adaptive systems. Machine learning has been used for a variety of reasons, ranging from learning a model of the environment of a system during operation to filtering large sets of possible configurations before analyzing them. While a body of work on the use of machine learning in self-adaptive systems exists, there is currently no systematic overview of this area. Such an overview is important for researchers to understand the state of the art and direct future research efforts. This article reports the results of a systematic literature review that aims at providing such an overview. We focus on self-adaptive systems that are based on a traditional Monitor-Analyze-Plan-Execute (MAPE)-based feedback loop. The research questions are centered on the problems that motivate the use of machine learning in self-adaptive systems, the key engineering aspects of learning in self-adaptation, and open challenges in this area. The search resulted in 6,709 papers, of which 109 were retained for data collection. Analysis of the collected data shows that machine learning is mostly used for updating adaptation rules and policies to improve system qualities, and managing resources to better balance qualities and resources. These problems are primarily solved using supervised and interactive learning with classification, regression, and reinforcement learning as the dominant methods. Surprisingly, unsupervised learning that naturally fits automation is only applied in a small number of studies. Key open challenges in this area include the performance of learning, managing the effects of learning, and dealing with more complex types of goals. From the insights derived from this systematic literature review, we outline an initial design process for applying machine learning in self-adaptive systems that are based on MAPE feedback loops.},
  keywords     = {feedback loops,MAPE-K,Self-adaptation}
}

@book{gortler_dimensionsanalyse_2011,
  title      = {{Dimensionsanalyse: Theorie der physikalischen Dimensionen mit Anwendungen}},
  shorttitle = {{Dimensionsanalyse}},
  author     = {G{\"o}rtler, H.},
  year       = {2011},
  month      = dec,
  day        = {1},
  address    = {Berlin, Heidelberg},
  edition    = {Softcover reprint of the original 1st ed. 1975 edition},
  publisher  = {Springer},
  abstract   = {Erfahrungen, die ich in wiederholt an der Universitat Freiburg abge\- haltenen Vorlesungen tiber die Methode der Dimensionsanalyse und das ModeHversuchswesen gemacht habe, haben mich veranlaBt, die\- ses Lehrbuch zu schreiben. Es erschien mir nachdiesen Erfahrungen unerlaBlich, daB die Dar\- steHung eines Gegenstandes, der auf dem Begriff der physikalischen Dimension aufbaut und aus der Dimensionshomogenitat aller physi\- kalischen Gleichungen ausgiebig Nutzen zieht, auf eine solide Theorie der physikalischen Dimensionen gegrtindet werden sollte. Auf dieser Grundlage sollte dann der fUr die Anwendungen fundamentale Satz, das sogenannte II-Theorem, in seiner vollen Allgemeinheit als Aus\- sage tiber alle Funktionen aus der Menge der dimensionshomogenen Funktionen bewiesen werden. Die Darstellung ist wie in den Vorlesungen so gewahlt, daB sie fUr Studierende der Physik, der N atur- und Ingenieurwissenschaften und der angewandten Mathematik mit den mathematischen Grundkennt\- nissen der ersten zwei Studiensemester verstandlich ist. Sie ver\- meidet bewuBt unnotige mathematische Abstraktionen. Beim mathe\- matischen Aufbau der Theorie wird dem Leser bei jedem Schritt eine ausfUhrliche physikalische Motivierung fUr das jeweilige Vorgehen gegeben. Von der Pflege der Anschauung als heuristischem Element wird reichlich Gebrauch gemacht. Hat der Studierende den erheblichen Nutzen der sich aus dieser The\- orie ergebenden Anwendungsmoglichkeiten erkannt, so soll ihn die\- ses Lehrbuch als Ratgeber wahrend seines weiteren Studiums beglei\- ten.},
  isbn       = {978-3-642-80873-9},
  langid     = {german}
}

@inproceedings{grua_self-adaptation_2019,
  title      = {Self-Adaptation in Mobile Apps: A Systematic Literature Study},
  shorttitle = {Self-Adaptation in Mobile Apps},
  booktitle  = {Proceedings of the 14th {{International Symposium}} on {{Software Engineering}} for {{Adaptive}} and {{Self-Managing Systems}}},
  author     = {Grua, Eoin Martino and Malavolta, Ivano and Lago, Patricia},
  year       = {2019},
  date       = {2019-05-25},
  series     = {{{SEAMS}} '19},
  pages      = {51--62},
  publisher  = {IEEE Press},
  address    = {Montreal, Quebec, Canada},
  location   = {Montreal, Quebec, Canada},
  doi        = {10.1109/SEAMS.2019.00016},
  url        = {http://doi.org/10.1109/SEAMS.2019.00016},
  urldate    = {2020-09-13},
  abstract   = {With their increase, smartphones have become more integral components of our lives but due to their mobile nature it is not possible to develop a mobile application the same way another software system would be built. In order to always provide the full service, a mobile application needs to be able to detect and deal with changes of context it may be presented with. A suitable method to achieve this goal is self-adaptation. However, as of today it is difficult to have a clear view of existing research on self-adaptation in the context of mobile applications. In this paper, we apply the systematic literature review methodology on selected peer-reviewed papers focusing on self-adaptability in the context of mobile applications. Out of 607 potentially relevant studies, we select 44 primary studies via carefully-defined exclusion and inclusion criteria. We use known modelling dimensions for self-adaptive software systems as our classification framework, which we apply to all selected primary studies. From the synthesized data we obtained, we produce an overview of the state of the art. The results of this study give a solid foundation to plan for future research and practice on engineering self-adaptive mobile applications.},
  keywords   = {Batteries,Data mining,Google,Hardware,Mobile applications,Mobile Apps,Self-adaptive systems,Software systems,Systematic Literature Study,Systematics}
}

@book{harris_digital_2012,
  title     = {Digital {{Design}} and {{Computer Architecture}}},
  author    = {Harris, David and Harris, Sarah},
  date      = {2012-08-07},
  year      = {2012},
  edition   = {2nd edition},
  publisher = {Morgan Kaufmann},
  address   = {Waltham, MA},
  location  = {Waltham, MA},
  abstract  = {Digital Design and Computer Architecture, Second Edition, takes a unique and modern approach to digital design, introducing the reader to the fundamentals of digital logic and then showing step by step how to build a MIPS microprocessor in both Verilog and VHDL. This new edition combines an engaging and humorous writing style with an updated and hands-on approach to digital design. It presents new content on I/O systems in the context of general purpose processors found in a PC as well as microcontrollers found almost everywhere.Beginning with digital logic gates and progressing to the design of combinational and sequential circuits, the book uses these fundamental building blocks as the basis for the design of an actual MIPS processor. It provides practical examples of how to interface with peripherals using RS232, SPI, motor control, interrupts, wireless, and analog-to-digital conversion. System Verilog and VHDL are integrated throughout the text in examples illustrating the methods and techniques for CAD-based circuit design. There are also additional exercises and new examples of parallel and advanced architectures, practical I/O applications, embedded systems, and heterogeneous computing, plus a new appendix on C programming to strengthen the connection between programming and processor architecture.This new edition will appeal to professional computer engineers and to students taking a course that combines digital logic and computer architecture.},
  isbn      = {978-0-12-394424-5},
  langid    = {english},
  pagetotal = {720}
}

@incollection{hauke_dimensional_2008,
  title     = {Dimensional {{Analysis}}},
  booktitle = {An {{Introduction}} to {{Fluid Mechanics}} and {{Transport Phenomena}}},
  author    = {Hauke, G.},
  editor    = {Hauke, G.},
  year      = {2008},
  series    = {Fluid {{Mechanics}} and {{Its Applications}}},
  pages     = {157--172},
  publisher = {Springer Netherlands},
  address   = {Dordrecht},
  doi       = {10.1007/978-1-4020-8537-6_9},
  urldate   = {2019-08-15},
  abstract  = {Even in the absence of chemical reactions, transport phenomena treat very complex physical processes. When chemical reactions are present, the complexity increases in an extraordinary manner. As seen in previous chapters, the calculation of the fluid field requires solving a set of coupled nonlinear partial differential equations. Even though the arrival of the computer allows us to obtain numerical solutions previously considered impossible, however, many industrial problems still cannot be solved in detail or with exactitude. For this to be possible, we must await an increase in the size and power of computers in various orders of magnitude. Until this happens, to uncover in detail and reliability the fluid dynamics of many industrial processes, one must resort to experiments. And the essential tool for laboratory tests is dimensional analysis.},
  isbn      = {978-1-4020-8537-6},
  langid    = {english},
  keywords  = {Critical Speed,Dimensional Analysis,Dimensional Matrix,Resistance Force,Speed Versus}
}

@article{hockney_computational_1995,
  title        = {Computational Similarity},
  author       = {Hockney, Roger W.},
  date         = {1995},
  year         = {1995},
  journal      = {Concurrency: Practice and Experience},
  journaltitle = {Concurrency: Practice and Experience},
  volume       = {7},
  number       = {2},
  pages        = {147--166},
  issn         = {1096-9128},
  doi          = {10.1002/cpe.4330070204},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4330070204},
  urldate      = {2024-02-04},
  abstract     = {The paper enunciates the principle of computational similarity, whereby calculations with the same values for certain dimensionless ratios are said to be ‘computationally similar’ and as a consequence have the same optimum self-speed-up and optimum number of processors. Based on a three-parameter description of the computer hardware, two dimensionless ratios, which are only a function of the problem size and the hardware parameters, completely determine the scaling. Contours of constant self-speed-up can be drawn on a two-dimensional dimensionless universal scaling diagram (DUSD). This diagram is for a particular class of timing expressions that can be shown to represent approximately the performance of a corresponding class of computer programs or benchmarks, but it applies to all computers describable by the three hardware parameters and to all problem sizes. Thus the dimensionless ratios play a similar role in the study of computer performance, as do the Reynolds and other dimensionless numbers in fluid dynamics. This dimensional analysis of computer performance is illustrated by the case of the FFT1 benchmark from the Southampton ‘Genesis’ distributed-memory benchmarks.},
  langid       = {english}
}

@misc{ibm_architectural_2005,
  title        = {An Architectural Blueprint for Autonomic Computing.},
  author       = {IBM, Inc},
  year         = {2005},
  date         = {2005-06},
  url          = {https://www-03.ibm.com/autonomic/pdfs/AC%20Blueprint%20White%20Paper%20V7.pdf},
  abstract     = {Autonomic Computing White Paper},
  langid       = {english},
  organization = {IBM}
}

@inproceedings{kacem_formal_2010,
  title     = {A {{Formal Approach}} to {{Enforcing Consistency}} in {{Self-adaptive Systems}}},
  booktitle = {Software {{Architecture}}},
  author    = {Kacem, Najla Hadj and Kacem, Ahmed Hadj and Drira, Khalil},
  editor    = {Babar, Muhammad Ali and Gorton, Ian},
  year      = {2010},
  date      = {2010},
  series    = {Lecture {{Notes}} in {{Computer Science}}},
  pages     = {279--294},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  location  = {Berlin, Heidelberg},
  doi       = {10.1007/978-3-642-15114-9_21},
  abstract  = {The ability of systems to adapt is increasingly seen as a necessary underlying capability for modern software systems. The resulting self-adaptive systems are not only supposed to cope with changes, but must also preserve their consistency. To deal with such challenges in a systematic way, the design of self-adaptive systems needs to be put on a formal basis. In this paper, we argue for the benefits of a formal yet extensible approach to behavioural adaptations of component-based system architectures. This approach provides the usage of alternative adaptation processes rather than being limited to a single one. The application of Coloured Petri Nets for modelling and analysing the adaptation processes proves to be useful to trust consistency preservation.},
  isbn      = {978-3-642-15114-9},
  langid    = {english},
  keywords  = {Incoming Request,Input Port,Linear Temporal Logic,Output Port,State Space Analysis}
}

@book{kan_metrics_2002,
  title     = {Metrics and {{Models}} in {{Software Quality Engineering}}},
  author    = {Kan, Stephen H.},
  year      = {2002},
  month     = jan,
  edition   = {2nd edition},
  publisher = {Addison-Wesley Professional},
  address   = {Boston, Mass.},
  abstract  = {Our society has become increasingly reliant on software in the past decade; businesses have learned that measuring the effectiveness of software projects can impact the bottom line; and quality is no longer an advantage in the software marketplace (it is a necessity). For these reasons, the demand for quality in software engineering has taken center stage in the twenty-first century. In this new edition, Stephen Kan presents a thoroughly updated overview and implementation guide for software engineers faced with the challenge of ensuring quality. The book balances theory, techniques, and real-life examples to provide practical guidelines in the practice of quality. Although there are equations and formulas presented, the book's focus remains on helping the reader understand and apply the metrics and models. With this book as a map, readers can navigate through the complex field of quality, and benefit their organization by improving their processes and products.},
  isbn      = {978-0-201-72915-3},
  langid    = {english}
}

@article{karam_buckinghampy_2021,
  title      = {{{BuckinghamPy}}: {{A Python}} Software for Dimensional Analysis},
  shorttitle = {{{BuckinghamPy}}},
  author     = {Karam, Mokbel and Saad, Tony},
  year       = {2021},
  month      = dec,
  journal    = {SoftwareX},
  volume     = {16},
  pages      = {100851},
  issn       = {2352-7110},
  doi        = {10.1016/j.softx.2021.100851},
  urldate    = {2023-03-04},
  abstract   = {The Buckingham Pi ({$\Pi$}) theorem is useful in determining the dimensionless terms that describe a physical phenomenon. The number of these terms grows with the number of variables. The traditional approach in identifying dimensionless quantities for a given system can be tedious and error-prone. BuckinghamPy~is a Python software that automates the traditional approach to generate all possible sets of dimensionless groups in ~format. In this article, we discuss the math behind the approach used, and then we validate the software using multiple examples. BuckinghamPy~serves as a helpful tool for experimentalists and engineers for both educational and research purposes.},
  langid     = {english},
  keywords   = {Buckingham  theorem,Dimensional analysis,Dimensionless terms,Python}
}

@techreport{kitchenham_guidelines_2007,
  type        = {2},
  title       = {Guidelines for Performing {{Systematic Literature Reviews}} in {{Software Engineering}}},
  author      = {Kitchenham, Barbara and Charters, Stuart},
  year        = {2007},
  month       = jul,
  address     = {Keele University},
  institution = {{Keele University and Durham University Joint Report}},
  abstract    = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social sci{\dots}(more)},
  langid      = {english}
}

@inproceedings{kredel_hierarchical_2015,
  title     = {A {{Hierarchical Model}} for the {{Analysis}} of {{Efficiency}} and {{Speed-Up}} of {{Multi-core Cluster-Computers}}},
  booktitle = {2015 10th {{International Conference}} on {{P2P}}, {{Parallel}}, {{Grid}}, {{Cloud}}, and {{Internet Computing}} ({{3PGCIC}})},
  author    = {Kredel, Heinz and Kruse, Hans G{\"u}nther and Richling, Sabine},
  year      = {2015},
  month     = nov,
  publisher = {IEEE},
  address   = {Krakow, Poland},
  pages     = {207--215},
  doi       = {10.1109/3PGCIC.2015.49},
  abstract  = {We develop a simple hierarchical model for the performance analysis of compute clusters assembled from multi-core compute nodes connected by a (high-speed) network. The performance is described by the dimensionless speed-up and efficiency in dependence on important hardware and application parameters. The hardware parameters are the number of compute nodes and the bandwidth the network, together with the number of cores per node, the theoretical performance of each core and the bandwidth of the main memory. The application parameters are the total number of operations performed on a number of bytes and the total number of bytes communicated between the processing units. In order to exemplify our concept we apply it to the scalar product of vectors, matrix multiplication, Linpack and FFT. Our previous performance models are contained as special cases in the new more comprehensive approach.},
  keywords  = {Analytical models,Bandwidth,Computational modeling,compute clusters,Computers,Hardware,Mathematical model,multi-core computers,Multicore processing,performance analysis,performance model,roof-line model}
}

@inproceedings{kredel_simple_2013,
  title     = {A {{Simple Concept}} for the {{Performance Analysis}} of {{Cluster-Computing}}},
  booktitle = {Supercomputing},
  author    = {Kredel, Heinz and Richling, Sabine and Kruse, Jan Philipp and Strohmaier, Erich and Kruse, Hans-G{\"u}nther},
  editor    = {Kunkel, Julian Martin and Ludwig, Thomas and Meuer, Hans Werner},
  year      = {2013},
  month     = jun,
  pages     = {165--180},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  doi       = {10.1007/978-3-642-38750-0_13},
  abstract  = {There seems to be a lack of reliable thumb rules to estimate the size and performance of clusters with respect to applications. Since modern cluster architecture is based on multi-cores we follow a concept derived by S. Williams et. al. for the analysis of such systems. The performance is described by the dimensionless speed-up in dependence on important hardware and application parameters. The hardware parameters are the number and the theoretical performance of each processing unit and the bandwidth of the network. The application parameters are the total number of operations performed on a number of bytes and the total number of bytes communicated between the processing units. In order to test our theoretical concept we apply our model to the scalar product of vectors, matrix multiplication, Linpack and the TOP500-list.},
  isbn      = {978-3-642-38750-0},
  langid    = {english},
  keywords  = {compute clusters,performance analysis,performance model,roofline model}
}

@book{len_bass_software_2012,
  title     = {Software {{Architecture}} in {{Practice}}},
  author    = {{Len Bass} and {Paul Clements} and {Rick Kazman}},
  year      = {2012},
  month     = oct,
  series    = {{{SEI Series}} in {{Software Engineering}}},
  edition   = {3rd Edition},
  publisher = {Addison-Wesley Professional},
  address   = {US},
  abstract  = {The award-winning and highly influential Software Architecture in Practice, Third Edition, has been substantially revised to reflect the latest developments in the field. In a real-world setting, the book once again introduces the concepts and best practices of software architecture---how a software system is structured and how that system's elements are meant to interact. Distinct from the details of implementation, algorithm, and data representation, an architecture holds the key to achieving system quality, is a reusable asset that can be applied to subsequent systems, and is crucial to a software organization's business strategy.},
  isbn      = {978-0-321-81573-6}
}

@article{mahdavi-hezavehi_systematic_2017,
  title    = {A Systematic Literature Review on Methods That Handle Multiple Quality Attributes in Architecture-Based Self-Adaptive Systems},
  author   = {{Mahdavi-Hezavehi}, Sara and Durelli, Vinicius H. S. and Weyns, Danny and Avgeriou, Paris},
  year     = {2017},
  month    = oct,
  journal  = {Information and Software Technology},
  volume   = {90},
  pages    = {1--26},
  issn     = {0950-5849},
  doi      = {10.1016/j.infsof.2017.03.013},
  urldate  = {2019-08-16},
  abstract = {Context Handling multiple quality attributes (QAs) in the domain of self-adaptive systems is an understudied research area. One well-known approach to engineer adaptive software systems and fulfill QAs of the system is architecture-based self-adaptation. In order to develop models that capture the required knowledge of the QAs of interest, and to investigate how these models can be employed at runtime to handle multiple quality attributes, we need to first examine current architecture-based self-adaptive methods. Objective In this paper we review the state-of-the-art of architecture-based methods for handling multiple QAs in self-adaptive systems. We also provide a descriptive analysis of the collected data from the literature. Method We conducted a systematic literature review by performing an automatic search on 28 selected venues and books in the domain of self-adaptive systems. As a result, we selected 54 primary studies which we used for data extraction and analysis. Results Performance and cost are the most frequently addressed set of QAs. Current self-adaptive systems dealing with multiple QAs mostly belong to the domain of robotics and web-based systems paradigm. The most widely used mechanisms/models to measure and quantify QAs sets are QA data variables. After QA data variables, utility functions and Markov chain models are the most common models which are also used for decision making process and selection of the best solution in presence of many alternatives. The most widely used tools to deal with multiple QAs are PRISM and IBM's autonomic computing toolkit. KLAPER is the only language that has been specifically developed to deal with quality properties analysis. Conclusions Our results help researchers to understand the current state of research regarding architecture-based methods for handling multiple QAs in self-adaptive systems, and to identity areas for improvement in the future. To summarize, further research is required to improve existing methods performing tradeoff analysis and preemption, and in particular, new methods may be proposed to make use of models to handle multiple QAs and to enhance and facilitate the tradeoffs analysis and decision making mechanism at runtime.}
}

@article{matsumoto_method_2017,
  title    = {A {{Method}} for {{Verifying Non-Functional Requirements}}},
  author   = {Matsumoto, Yuuma and Shirai, Sayaka and Ohnishi, Atsushi},
  year     = {2017},
  month    = jan,
  journal  = {Procedia Computer Science},
  series   = {Knowledge-{{Based}} and {{Intelligent Information}} \& {{Engineering Systems}}: {{Proceedings}} of the 21st {{International Conference}}, {{KES-20176-8 September}} 2017, {{Marseille}}, {{France}}},
  volume   = {112},
  pages    = {157--166},
  issn     = {1877-0509},
  doi      = {10.1016/j.procs.2017.08.006},
  urldate  = {2019-08-16},
  abstract = {In order to verify the correctness of functional requirements, we have been developing a verification method of the correctness of functional requirements specification using the Requirements Frame model. In this paper, we introduce a verification method of non-functional requirements specification, especially time-response requirements and usability requirements written with a natural language. We establish a verification method by extending the Requirements Frame model. We have also developed a prototype system based on the method using Java. The extended Requirements Frame model and the verification method will be illustrated with examples.},
  keywords = {Non-functional requirements,Requirements frame,Time-Response requirements,Usability requirements,Verification of non-functional requirements}
}

@book{mcmahon_size_1983,
  title     = {On {{Size}} and {{Life}}},
  author    = {McMahon, Thomas and Bonner, John Tyler},
  year      = {1983},
  month     = jun,
  edition   = {1st edition},
  publisher = {Scientific American Books - W. H. Freeman \& Co.},
  address   = {New York},
  abstract  = {Considers the role of shape and size in natural selection, looks at growth, biological structure, and locomotion, and discusses the effect of scale on living organisms},
  isbn      = {978-0-7167-5000-0},
  langid    = {english}
}

@book{michael_how_2016,
  title     = {How to {{Scale-Up}} a {{Wet Granulation End Point Scientifically}}},
  author    = {Michael, Levin},
  year      = {2016},
  publisher = {Elsevier},
  doi       = {10.1016/C2014-0-04970-2},
  urldate   = {2019-08-13},
  address   = {US},
  abstract  = {How to Scale-Up a Wet Granulation End Point Scientifically provides a single-source devoted to all relevant information on the scale-up of a wet granulation end point. Contents include a general description, problem identification, and theoretical background with supporting literature, case studies, potential solutions, and more. By outlining issues related to scale-up and end-point determination, and then using practical examples and advice to address these issues, How to Scale-Up a Wet Granulation End Point Scientifically is a valuable and essential resource for all those pharmaceutical scientists and technologists engaged in the granulation process.},
  copyright = {Michael Levin, PhD, Milev, LLC, Pharmaceutical Technology Consulting, Measurement Control Corporation (MCC)},
  isbn      = {978-0-12-803522-1},
  langid    = {english}
}

@misc{noauthor_ieee_nodate-1,
  title        = {{{IEEE}} 1061-1998: {{Standard}} for a {{Software Quality Metrics Methodology}}},
  journal      = {IEEE Standards Association},
  urldate      = {2024-11-15},
  howpublished = {https://standards.ieee.org/ieee/1061/1549/},
  langid       = {english}
}

@misc{noauthor_ptolemy_nodate,
  title        = {Ptolemy {{II Home Page}}},
  urldate      = {2019-12-13},
  howpublished = {https://ptolemy.berkeley.edu/ptolemyII/index.htm}
}

@article{numrich_computational_2008,
  title    = {Computational Forces in the {{Linpack}} Benchmark},
  author   = {Numrich, Robert W.},
  year     = {2008},
  month    = sep,
  journal  = {Journal of Parallel and Distributed Computing},
  volume   = {68},
  number   = {9},
  pages    = {1283--1290},
  issn     = {0743-7315},
  doi      = {10.1016/j.jpdc.2008.02.008},
  urldate  = {2023-06-02},
  abstract = {Dimensional analysis reduces a complicated ten-parameter formula for the execution time of the Linpack benchmark to a simpler two-parameter formula. These two parameters are ratios of software forces and hardware forces that determine a self-similarity surface. Machines move along paths on this surface as the problem size and the number of processors change. Two machines scale the same way, they move along the same path, if they have the same hardware forces. To design efficient algorithms, the programmer must produce software forces large enough to overcome the hardware forces. Modern machines have larger hardware forces than older machines and are harder to program.},
  langid   = {english},
  keywords = {Computational force,Computational intensity,Dimensional analysis,Linpack benchmark,Parallel numerical algorithms,Performance analysis,Scalability}
}

@article{numrich_computational_2009,
  title    = {Computational Forces in the {{SAGE}} Benchmark},
  author   = {Numrich, Robert W.},
  year     = {2009},
  month    = mar,
  journal  = {Journal of Parallel and Distributed Computing},
  volume   = {69},
  number   = {3},
  pages    = {315--325},
  issn     = {0743-7315},
  doi      = {10.1016/j.jpdc.2008.12.001},
  urldate  = {2024-02-04},
  abstract = {Dimensional analysis applied to a complicated timing formula for the SAGE benchmark yields new insight into the limits to scalability. A single surface, defined by two curvilinear coordinates, describes the parallel efficiency of the benchmark. Each machine, as a function of the number of processors, follows its own path on the surface determined by dimensionless ratios of hardware forces to software forces. Two machines with the same ratios follow the same path and are self-similar, even though the numerical value of each individual force may be different. For this benchmark, latency effects are unimportant relative to bandwidth effects because of the slab decomposition used to distribute the problem across processors. To a good first-order approximation, a single force ratio describes the efficiency as a function of the number of processors. A simpler model, with a single dimensionless exponent, describes the first-order behavior of the computational power as a function of the number of processors.},
  keywords = {Benchmark analysis,Computational force,Computational intensity,Dimensional analysis,Parallel algorithms,Scaling,Self-similarity}
}

@article{numrich_computational_2010,
  title    = {The Computational Energy Spectrum of a Program as~It~Executes},
  author   = {Numrich, Robert W.},
  year     = {2010},
  month    = may,
  journal  = {The Journal of Supercomputing},
  volume   = {52},
  number   = {2},
  pages    = {119--134},
  issn     = {1573-0484},
  doi      = {10.1007/s11227-009-0273-x},
  urldate  = {2024-02-04},
  abstract = {This paper describes how to interpret a program's performance in terms of its computational energy spectrum. High spikes in the spectrum correspond to important events during execution, such as cache misses, for example, and their positions show when they happen and how they effect other events. The area under the spectrum measures a program's size in terms of the computational action norm, a measure of how efficiently it moves through computational phase space. The distance from one program to another is the area between their action curves. The measured energy spectra for a set of real programs executing on real hardware support the conjecture that the best program generates the least action, the Principle of Computational Least Action.},
  langid   = {english},
  keywords = {Computational action norm,Computational energy spectrum,Performance analysis,Principle of computational least action}
}

@article{numrich_computer_2014,
  title    = {Computer Performance Analysis and the {{Pi Theorem}}},
  author   = {Numrich, Robert W.},
  year     = {2014},
  month    = feb,
  journal  = {Computer Science - Research and Development},
  volume   = {29},
  number   = {1},
  pages    = {45--71},
  issn     = {1865-2034},
  doi      = {10.1007/s00450-010-0147-8},
  urldate  = {2023-03-04},
  abstract = {This paper applies the Pi Theorem of dimensional analysis to a representative set of examples from computer performance analysis. It is a survey paper that takes a different look at problems involving latency, bandwidth, cache-miss ratios, and the efficiency of parallel numerical algorithms. The Pi Theorem is the fundamental tool of dimensional analysis, and it applies to problems in computer performance analysis just as well as it does to problems in other sciences. Applying it requires the definition of a system of measurement appropriate for computer performance analysis with a consistent set of units and dimensions. Then a straightforward recipe for each specific problem reduces the number of independent variables to a smaller number of dimensionless parameters. Two machines with the same values of these parameters are self-similar and behave the same way. Self-similarity relationships emphasize how machines are the same rather than how they are different. The Pi Theorem is simple to state and simple to prove, using purely algebraic methods, but the results that follow from it are often surprising and not simple at all. The results are often unexpected but they almost always reveal something new about the problem at hand.},
  keywords = {Bandwidth,Cache behavior,Computational force,Computational intensity,Dimensional analysis,Latency,Parallel algorithms,Performance analysis,Performance metrics,Pi Theorem,Scaling}
}

@inproceedings{numrich_dimensional_2008,
  title     = {Dimensional {{Analysis Applied}} to a {{Parallel QR Algorithm}}},
  booktitle = {Parallel {{Processing}} and {{Applied Mathematics}}},
  author    = {Numrich, Robert W.},
  editor    = {Wyrzykowski, Roman and Dongarra, Jack and Karczewski, Konrad and Wasniewski, Jerzy},
  year      = {2008},
  pages     = {148--155},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
  doi       = {10.1007/978-3-540-68111-3_16},
  abstract  = {We apply dimensional analysis to a formula for execution time for a QR algorithm from a paper by Henry and van de Geijn. We define a single efficiency surface that reduces performance analysis for this algorithm to an exercise in differential geometry. As the problem size and the number of processors change, different machines move along different paths on the surface determined by two computational forces specific to each machine. We show that computational force, also called computational intensity, is a unifying concept for understanding the performance of parallel numerical algorithms.},
  isbn      = {978-3-540-68111-3},
  langid    = {english},
  keywords  = {computational force,computational intensity,dimensional analysis,parallel numerical algorithms,performance analysis,Scalability}
}

@inproceedings{numrich_metric_2005,
  title     = {A Metric Space for Productivity Measurement in Software Development},
  booktitle = {Proceedings of the Second International Workshop on {{Software}} Engineering for High Performance Computing System Applications},
  author    = {Numrich, Robert W. and Hochstein, Lorin and Basili, Victor R.},
  date      = {2005-05-15},
  year      = {2005},
  series    = {{{SE-HPCS}} '05},
  pages     = {13--16},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  location  = {New York, NY, USA},
  doi       = {10.1145/1145319.1145324},
  url       = {https://dl.acm.org/doi/10.1145/1145319.1145324},
  urldate   = {2024-02-03},
  abstract  = {We define a metric space to measure the contributions of individual programmers to a software development project. It allows us to measure the distance between the contributions of two different programmers as well as the absolute contribution of each individual programmer. Our metric is based on an action function that provides a picture of how one programmer's approach differs from another at each instance of time during the project. We apply our metric to data we collected from students taking a course in parallel programming. We display the pictures for two students who showed approximately equal contributions but who followed very different paths through the course.},
  isbn      = {978-1-59593-117-7}
}

@article{numrich_metric_2008,
  title    = {A Metric Space for Computer Programs and the Principle of Computational Least Action},
  author   = {Numrich, Robert W.},
  year     = {2008},
  month    = mar,
  journal  = {The Journal of Supercomputing},
  volume   = {43},
  number   = {3},
  pages    = {281--298},
  issn     = {0920-8542},
  doi      = {10.1007/s11227-007-0145-1},
  urldate  = {2024-02-04},
  abstract = {We define a normed metric space for computer programs and derive from it the Principle of Computational Least Action. In our model, programs follow trajectories determined by Newton's equation of motion in an abstract computational phase space and generate computational action as they evolve. A program's action norm is the L 1 -norm of its action function, and its distance from other programs is the distance derived from the action norm. The Principle of Computational Least Action states the goal of performance optimization as finding the program with the smallest action norm. We illustrate this principle by analyzing a simple program.},
  keywords = {Impact Force,Instruction Sequence,Memory Bandwidth,Phase Portrait,Power Series Expansion}
}

@article{numrich_note_2007,
  title    = {A Note on Scaling the {{Linpack}} Benchmark},
  author   = {Numrich, Robert W.},
  year     = {2007},
  month    = apr,
  journal  = {Journal of Parallel and Distributed Computing},
  volume   = {67},
  number   = {4},
  pages    = {491--498},
  issn     = {0743-7315},
  doi      = {10.1016/j.jpdc.2007.01.002},
  urldate  = {2024-02-04},
  abstract = {Dimensional analysis yields a new scaling formula for the Linpack benchmark. The computational power r(p0,q0) on a set of processors decomposed into a (p0,q0) grid determines the computational power r(p,q) on a set of processors decomposed into a (p,q) grid by the formula r(p,q)=(p/p0){$\alpha$}(q/q0){$\beta$}r(p0,q0). The two scaling parameters {$\alpha$} and {$\beta$} measure interprocessor communication overhead required by the algorithm. A machine that scales perfectly corresponds to {$\alpha$}={$\beta$}=1; a machine that scales not at all corresponds to {$\alpha$}={$\beta$}=0. We have determined the two scaling parameters by imposing a fixed-time constraint on the problem size such that the execution time remains constant as the number of processors changes. Results for a collection of machines confirm that the formula suggested by dimensional analysis is correct. Machines with the same values for these parameters are self-similar. They scale the same way even though the details of their specific hardware and software may be quite different.},
  keywords = {Dimensional analysis,Linpack benchmark,Performance analysis,Pi Theorem,Scaling,Self-similarity}
}

@article{numrich_performance_2004,
  title    = {Performance {{Metrics Based}} on {{Computational Action}}},
  author   = {Numrich, Robert W.},
  year     = {2004},
  month    = nov,
  journal  = {International Journal of High Performance Computing Applications},
  volume   = {18},
  number   = {4},
  pages    = {449--458},
  issn     = {1094-3420},
  doi      = {10.1177/1094342004048538},
  urldate  = {2024-02-04},
  abstract = {We propose a new performance metric based on computational action. We examine work as it evolves in time and compute computational action as the integral of the work function over time. We compare the action generated at less than full power with the action that could have been generated at full power. We claim that the goal of performance optimization is to minimize lost, or wasted, action. We calculate our metric for some computers in the Top500 list (http://www.top500.org) and propose a new ranking based on least action wasted. When work is a function of the resources applied, we use the classical techniques of the calculus of variations to minimize wasted action. From the result of this exercise, we calculate productivity as the ratio of work produced to resources used.},
  keywords = {computational action,computational work,Performance metrics}
}

@article{numrich_performance_2009,
  title    = {A~Performance Model with a~Fixed Point for a~Molecular Dynamics Kernel},
  author   = {Numrich, Robert W. and Heroux, Michael A.},
  year     = {2009},
  month    = jun,
  journal  = {Computer Science - Research and Development},
  volume   = {23},
  number   = {3},
  pages    = {195--201},
  issn     = {1865-2042},
  doi      = {10.1007/s00450-009-0086-4},
  urldate  = {2024-02-04},
  abstract = {Analysis of a~timing formula for a~molecular dynamics kernel reveals an equivalence classof parallel machines with a~fixed point that is independent of the particular machine in the class.Three different machines, CRAY, IBM and SGI, are self-similar in that they follow the same path along a~performancesurface as the processor count and problem size change. The path is attracted to a~fixed point thatlimits performance, the same fixed point for all three machines. An analytic formula, with two parametersdetermined from measured data, reproduces the path along the surface.},
  langid   = {english},
  keywords = {Computational Force,Cutoff Distance,Neighbor List,Problem Size,Symplectic Integrator}
}

@article{numrich_self-similarity_2011,
  title    = {Self-Similarity of Parallel Machines},
  author   = {Numrich, Robert W. and Heroux, Michael A.},
  year     = {2011},
  month    = feb,
  journal  = {Parallel Computing},
  volume   = {37},
  number   = {2},
  pages    = {69--84},
  issn     = {0167-8191},
  doi      = {10.1016/j.parco.2010.11.003},
  urldate  = {2023-06-04},
  abstract = {Self-similarity is a property of physical systems that describes how to scale parameters such that dissimilar systems appear to be similar. Computer systems are self-similar if certain ratios of computational forces, also known as computational intensities, are equal. Two machines with different computational power, different network bandwidth and different inter-processor latency behave the same way if they have the same ratios of forces. For the parallel conjugate gradient algorithm studied in this paper, two machines are self-similar if and only if the ratio of one force describing latency effects to another force describing bandwidth effects is the same for both machines. For the two machines studied in this paper, this ratio, which we call the mixing coefficient, is invariant as problem size and processor count change. The two machines have the same mixing coefficient and belong to the same equivalence class.},
  langid   = {english},
  keywords = {Benchmark analysis,Computational force,Computational intensity,Dimensional analysis,Equivalence class,Mixing coefficient,Parallel algorithms,Scaling,Self-similarity}
}

@article{ortega_dimensionless_2018,
  title    = {Dimensionless {{Numbers}} for {{Plant Biology}}},
  author   = {Ortega, Joseph K. E.},
  year     = {2018},
  month    = jan,
  journal  = {Trends in Plant Science},
  volume   = {23},
  number   = {1},
  pages    = {6--9},
  issn     = {1360-1385},
  doi      = {10.1016/j.tplants.2017.09.020},
  urldate  = {2019-08-15},
  abstract = {Dimensionless numbers are ubiquitous in the physical sciences because they provide insight into physical processes, organize large quantities of data, facilitate `scale analysis' and establish `similarity'. Here I explore the use of dimensionless numbers in plant biology, focusing on the expansive growth rate of plant, fungal, and algal cells.}
}

@book{p.e_applied_2006,
  title     = {Applied {{Dimensional Analysis}} and {{Modeling}}},
  author    = {P.E, Thomas Szirtes Ph D.},
  year      = {2006},
  month     = dec,
  edition   = {2nd edition},
  publisher = {Butterworth-Heinemann},
  address   = {Amsterdam New York},
  abstract  = {Applied Dimensional Analysis and Modeling provides the full mathematical background and step-by-step procedures for employing dimensional analyses, along with a wide range of applications to problems in engineering and applied science, such as fluid dynamics, heat flow, electromagnetics, astronomy and economics. This new edition offers additional worked-out examples in mechanics, physics, geometry, hydrodynamics, and biometry.Covers 4 essential aspects and applications: principal characteristics of dimensional systems, applications of dimensional techniques in engineering, mathematics and geometry, applications in biosciences, biometry and economics, applications in astronomy and physicsOffers more than 250 worked-out examples and problems with solutionsProvides detailed descriptions of techniques of both dimensional analysis and dimensional modeling},
  isbn      = {978-0-12-370620-1},
  langid    = {english}
}

@article{petersen_guidelines_2015,
  title      = {Guidelines for Conducting Systematic Mapping Studies in Software Engineering: {{An}} Update},
  shorttitle = {Guidelines for Conducting Systematic Mapping Studies in Software Engineering},
  author     = {Petersen, Kai and Vakkalanka, Sairam and Kuzniarz, Ludwik},
  year       = {2015},
  month      = aug,
  journal    = {Information and Software Technology},
  volume     = {64},
  pages      = {1--18},
  issn       = {0950-5849},
  doi        = {10.1016/j.infsof.2015.03.007},
  urldate    = {2023-02-23},
  abstract   = {Context Systematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and SLR guidelines. Objective To identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly. Method We conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment). Results In a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given. Conclusion The most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings.},
  langid     = {english},
  keywords   = {Guidelines,Software engineering,Systematic mapping studies}
}

@inproceedings{petersen_systematic_2008,
  author    = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
  title     = {Systematic {{Mapping Studies}} in {{Software Engineering}}},
  year      = {2008},
  address   = {Swindon, GBR},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}} },
  pages     = {68–77},
  numpages  = {10},
  keywords  = {evidence based software engineering, systematic mapping studies, systematic reviews},
  location  = {Italy},
  series    = {EASE'08},
  publisher = {BCS Learning \& Development},
  doi       = {10.14236/ewic/EASE2008.8},
  abstract  = {BACKGROUND: A software engineering systematic map is a defined method to build a classification scheme and structure a software engineering field of interest. The analysis of results focuses on frequencies of publications for categories within the scheme. Thereby, the coverage of the research field can be determined. Different facets of the scheme can also be combined to answer more specific research questions.OBJECTIVE: We describe how to conduct a systematic mapping study in software engineering and provide guidelines. We also compare systematic maps and systematic reviews to clarify how to chose between them. This comparison leads to a set of guidelines for systematic maps.METHOD: We have defined a systematic mapping process and applied it to complete a systematic mapping study. Furthermore, we compare systematic maps with systematic reviews by systematically analyzing existing systematic reviews.RESULTS: We describe a process for software engineering systematic mapping studies and compare it to systematic reviews. Based on this, guidelines for conducting systematic maps are defined.CONCLUSIONS: Systematic maps and reviews are different in terms of goals, breadth, validity issues and implications. Thus, they should be used complementarily and require different methods (e.g., for analysis).}
}

@article{markucic_optimization_2018,
  title        = {Optimization Parameters of the Heart Pump Design},
  author       = {Markučič, V and Krizmanić, S and Volarić, F},
  date         = {2018-07},
  year         = {2018},
  journal      = {IOP Conference Series: Materials Science and Engineering},
  journaltitle = {IOP Conference Series: Materials Science and Engineering},
  shortjournal = {IOP Conf. Ser.: Mater. Sci. Eng.},
  volume       = {393},
  number       = {1},
  pages        = {012125},
  publisher    = {IOP Publishing},
  issn         = {1757-899X},
  doi          = {10.1088/1757-899X/393/1/012125},
  url          = {https://doi.org/10.1088/1757-899X/393/1/012125},
  urldate      = {2025-12-05},
  abstract     = {In this paper, research of optimization parameters of continuous flow heart pump is presented. The application of centrifugal pumps as heart assist devices imposes design limitations on the geometry of the heart pump. Geometry and pump parameters affect the performance and the hemocompatibility of the heart pump. The main quality assessment factor for heart pump is the pump hemocompatibility i.e., the amount of mechanical damage caused by a pump on blood cells. Besides stagnation zones and recirculation zones, wall shear stress is parameter that is used to predict pump hemocompatibility. Second important factor is minimal volume of heart pump with acceptable anatomical fitting. Additional factors are high efficiency and durability. The aim of the research is to propose the optimal design of bladeless centrifugal heart pump. The dimensionless optimization parameters of the heart pump design are derived from Navier - Stokes equation. In conclusion, dimensionless optimization parameters of bladeless centrifugal continuous flow heart pump are presented.},
  langid       = {english},
}


@article{pohly_data-driven_2021,
  title    = {Data-Driven {{CFD}} Scaling of Bioinspired {{Mars}} Flight Vehicles for Hover},
  author   = {Pohly, Jeremy A. and Kang, Chang-kwon and Landrum, D. Brian and Bluman, James E. and Aono, Hikaru},
  year     = {2021},
  month    = mar,
  journal  = {Acta Astronautica},
  volume   = {180},
  pages    = {545--559},
  issn     = {0094-5765},
  doi      = {10.1016/j.actaastro.2020.12.037},
  urldate  = {2023-02-19},
  abstract = {One way to improve our model of Mars is through aerial sampling and surveillance, which could provide information to augment the observations made by ground-based exploration and satellite imagery. Flight in the challenging ultra-low-density Martian environment can be achieved with properly scaled bioinspired flapping wing vehicle configurations that utilize the same high lift producing mechanisms that are employed by insects on Earth. Through dynamic scaling of wings and kinematics, we investigate the ability to generate solutions for a broad range of flapping wing flight vehicles with masses ranging from insects O(10-3) kg to the Mars helicopter Ingenuity O(100) kg. A scaling method based on a neural-network trained on 3D Navier-Stokes solutions is proposed to determine approximate wing size and kinematic values that generate bioinspired hover solutions. We demonstrate that a family of solutions exists for designs that range from 1 to 1000~g, which are verified and examined using a 3D Navier-Stokes solver. Our results reveal that unsteady lift enhancement mechanisms, such as delayed stall and rotational lift, are present in the bioinspired solutions for the scaled vehicles hovering in Martian conditions. These hovering vehicles exhibit payloads of up to 1~kg and flight times on the order of 100~min when considering the respective limiting cases of the vehicle mass being comprised entirely of payload or entirely of a battery and neglecting any transmission inefficiencies. This method can help to develop a range of Martian flying vehicle designs with mission viable payloads, range, and endurance.},
  langid   = {english},
  keywords = {Bioinspired unsteady aerodynamics,Flapping wing,Mars exploration,Mars flight vehicle concept}
}

@inproceedings{pohly_scaling_2019,
  title     = {Scaling {{Bioinspired Mars Flight Vehicles}} for {{Hover}}},
  booktitle = {{{AIAA Scitech}} 2019 {{Forum}}},
  author    = {Pohly, Jeremy A. and Kang, Chang-kwon and Sridhar, Madhu and Landrum, D Brian and Fahimi, Farbod and Mesmer, Bryan and Bluman, James E. and Aono, Hikaru and Lee, Taeyoung},
  year      = {2019},
  month     = jan,
  pages     = {1--15},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  address   = {San Diego, California},
  doi       = {10.2514/6.2019-0567},
  urldate   = {2021-11-22},
  isbn      = {978-1-62410-578-4},
  langid    = {english},
  abstract = {With the resurgent interest in landing humans on Mars, it is critical that our understanding of the Martian environment is complete and accurate. One way to improve our model of the red planet is through aerial surveillance, which provides information that augments the observations made by ground-based exploration and satellite imagery. Although the ultra-low-density Mars environment has previously stymied designs for achieving flight on Mars, bioinspired solutions for flapping wing flight can utilize the same high lift producing mechanisms employed by insects on Earth. Motivated by the current technologies for terrestrial flapping wing aerial vehicles on Earth, we seek solutions for a 5 gram bioinspired flapping wing aerial vehicle for flight on Mars. A zeroth-order method is proposed to determine approximate wing and kinematic values that generate bioinspired hover solutions. We demonstrate that a family of solutions exists for designs that are O(101) g, which are verified using a 3D Navier-Stokes solver. Our results show that unsteady lift enhancement mechanisms, such as delayed stall and rotational lift, are present in the bioinspired solution for a 5 g flapping wing vehicle hovering in Mars conditions, verifying that the zeroth-order method is a useful design tool. As a result, it is possible to design a family of bioinspired flapping wing robots for Mars by augmenting the adverse effects of the ultra-low density with large wings that exploit the advantages of unsteady lift enhancement mechanisms used by insects on Earth.}
}

@inproceedings{porter_survey_2020,
  title      = {A {{Survey}} of {{Methodology}} in {{Self-Adaptive Systems Research}}},
  booktitle  = {2020 {{IEEE International Conference}} on {{Autonomic Computing}} and {{Self-Organizing Systems}} ({{ACSOS}})},
  author     = {Porter, Barry and Filho, Roberto Rodrigues and Dean, Paul},
  date       = {2020-08},
  year       = {2020},
  pages      = {168--177},
  doi        = {10.1109/ACSOS49614.2020.00039},
  publisher  = {IEEE},
  address    = {Washington, DC, USA},
  location   = {Washington, DC, USA},
  abstract   = {Major research venues on autonomic and self-adaptive systems have been active for 16 years, exploring and building on the seminal vision of autonomic computing in 2003. We study the current trajectory and progress of the research field towards this vision, surveying the research questions that are asked by researchers and the methodological practice that they employ in order to answer these questions. We survey contributions under this lens across the three main venues for primary research in autonomic and self-adaptive systems work: ICAC, SASO, and SEAMS. We examine the last three years of contributions from each venue, totaling 210 publications, to gain an understanding of the dominant current research questions and methodological practice - and what this shows us about the progress of the field. Our major findings include: (i) most research questions still focus one level below the highest autonomy level vision; (ii) methodological practice is split almost evenly between real-world experiments and simulation; (iii) a high level of positive results bias exists in publications; and (iv) there are low levels of repeatability across most contributions.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Autonomic Computing}} and {{Self-Organizing Systems}} ({{ACSOS}})},
  keywords   = {Adaptation models,Adaptive systems,Computational modeling,Encoding,Optimization,Security,Tools}
}

@incollection{raibulet_chapter_2017,
  title     = {Chapter 13 - {{An Overview}} on {{Quality Evaluation}} of {{Self-Adaptive Systems}}},
  booktitle = {Managing {{Trade-Offs}} in {{Adaptable Software Architectures}}},
  author    = {Raibulet, C. and Arcelli Fontana, F. and Capilla, R. and Carrillo, C.},
  editor    = {Mistrik, Ivan and Ali, Nour and Kazman, Rick and Grundy, John and Schmerl, Bradley},
  year      = {2017},
  month     = jan,
  pages     = {325--352},
  publisher = {Morgan Kaufmann},
  address   = {Boston},
  doi       = {10.1016/B978-0-12-802855-1.00013-7},
  isbn      = {978-0-12-802855-1},
  keywords  = {Evaluation,Quality attributes,Self-adaptive systems,Self-adaptivity,Software metrics}
}

@article{ruzicka_dimensionless_2008,
  title    = {On Dimensionless Numbers},
  author   = {Ruzicka, M. C.},
  year     = {2008},
  month    = aug,
  journal  = {Chemical Engineering Research and Design},
  volume   = {86},
  number   = {8},
  pages    = {835--868},
  issn     = {0263-8762},
  doi      = {10.1016/j.cherd.2008.03.007},
  urldate  = {2019-08-13},
  abstract = {The goal is to provide a little review on dimensionless numbers, commonly encountered in chemical engineering. Both their sources are considered: dimensional analysis and scaling of governing equations with boundary conditions. The numbers produced by scaling of equation are presented for transport of momentum, heat and mass. Momentum transport is considered in both single-phase and multi-phase flows. The numbers obtained are assigned the physical meaning, and their mutual relations are highlighted. Certain drawbacks of building correlations based on dimensionless numbers are pointed out.},
  keywords = {Correlations,Dimensional analysis,Dimensionless numbers,Multi-phase flow,Scaling of boundary conditions,Scaling of equations,Single-phase flow}
}

@article{saputri_application_2020,
  title        = {The {{Application}} of {{Machine Learning}} in {{Self-Adaptive Systems}}: {{A Systematic Literature Review}}},
  shorttitle   = {The {{Application}} of {{Machine Learning}} in {{Self-Adaptive Systems}}},
  author       = {Saputri, T. R. D. and Lee, S.-W.},
  date         = {2020-10-05},
  year         = {2020},
  journaltitle = {IEEE Access},
  journal      = {IEEE Access},
  volume       = {8},
  pages        = {205948--205967},
  issn         = {2169-3536},
  doi          = {10.1109/ACCESS.2020.3036037},
  abstract     = {Context: Self-adaptive systems have been studied in software engineering over the past few decades attempting to address challenges within the field. There is a continuous significant need to fully understand the behavior and characteristics of the systems that operate in dynamic environments. By learning the behavior pattern of the environment, we can avoid unnecessary adaptations imbalance efforts for adaptation. As such, there exist research in the area of machine learning aimed at understanding dynamic environments regarding self-adaptive systems. Objective: This study aims to help software practitioners to address adaptation concerns by performing a systematic literature review that provides a comprehensive overview of using machine learning (ML) in self-adaptive systems. We summarize state-of-the-art Of the ML approaches used to handle self-adaptation to help software engineers in the proper selection of ML techniques based on the adaptation concern. Method: This review examines research published between 2001 and 2019 on ML implementation in self-adaptive systems, focusing on the adaptation aspects and purposes. The review was conducted by analyzing major scientific databases that resulted in 78 primary studies from 315 papers from an automatic search. Result: Finally, this study recommends three future research directions to enhance the application of machine learning in self-adaptive systems.},
  eventtitle   = {{{IEEE Access}}},
  keywords     = {adaptation,adaptation aspects,Adaptation models,Bibliographies,dynamic environments,learning (artificial intelligence),machine learning,Machine learning,Market research,reviews,self-adaptive systems,software engineering,software engineers,Synthetic aperture sonar,systematic literature review,Systematic literature review,Systematics,Taxonomy,unnecessary adaptations imbalance efforts}
}

@incollection{schmerl_chapter_2017,
  title     = {Chapter 1 - {{Managing Trade-Offs}} in {{Adaptable Software Architectures}}},
  booktitle = {Managing {{Trade-Offs}} in {{Adaptable Software Architectures}}},
  author    = {Schmerl, B. and Kazman, R. and Ali, N. and Grundy, J. and Mistrik, I.},
  editor    = {Mistrik, Ivan and Ali, Nour and Kazman, Rick and Grundy, John and Schmerl, Bradley},
  year      = {2017},
  date      = {2017-01-01},
  pages     = {1--13},
  publisher = {Morgan Kaufmann},
  location  = {Boston},
  address   = {Boston, USA},
  doi       = {10.1016/B978-0-12-802855-1.00001-0},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780128028551000010},
  isbn      = {978-0-12-802855-1},
  keywords  = {Adaptive architecture,Self-adaptive systems,Trade-offs}
}

@inproceedings{severeyn_estimation_2019,
  title     = {Estimation of Invasive Physiological Parameters from Non-Invasive Parameters Using Dimensionless Numbers and {{Monte Carlo}} Cross-Validation},
  booktitle = {2019 {{XXII Symposium}} on {{Image}}, {{Signal Processing}} and {{Artificial Vision}} ({{STSIVA}})},
  author    = {Severeyn, E. and Vel{\'a}squez, J. and Herrera, H. and Perpi{\~n}an, G. and Wong, S. and Altuve, M.},
  date      = {2019-04-24},
  year      = {2019},
  publisher = {IEEE},
  address   = {Bucaramanga, Colombia},
  month     = apr,
  pages     = {1--5},
  doi       = {10.1109/STSIVA.2019.8730252},
  abstract  = {According to NCEP-ATPIII criterion, metabolic syndrome (MS) diagnosis is based in the measurement of invasive (triglycerides, HDL, glucose) and non invasive variables (height, weight, waist circumference). The aim of this work is find, since dimensionless numbers design from physiological ({$\pi$}1IS, {$\pi$}2IS) and heart rate variability ({$\pi$}1HRV, {$\pi$}2HRV) parameters, three polynomial equations ({$\pi$}1IS=f({$\pi$}2HRV), {$\pi$}2IS=f({$\pi$}1HRV), {$\pi$}2IS=f({$\pi$}2HRV)) that relate invasive with non invasive variables. In this sense, a fitting using Monte Carlo cross validation (MCCV) was performed. A database of 40 subjects (25 control subjects and 15 subjects with MS) was employed. The results suggest that MCCV improves the coefficient of determination (R2), compared to the application of the least squares method only, in each polynomial: {$\pi$}1IS=f({$\pi$}2HRV) (R2=0.62 vs. 0.21), {$\pi$}2IS=f({$\pi$}1HRV) (R2=0.62 vs. 0.36) and {$\pi$}2IS=f({$\pi$}2HRV) (R2=0.56 vs. 0.19). The fitting by MCCV allows the estimation of invasive from non invasive parameters.},
  keywords  = {Correlation,database,database management systems,Databases,dimensionless numbers,diseases,Empirical Correlation,Fitting,Hardware design languages,Heart rate variability,invasive physiological parameters,Mathematical model,medical computing,medical disorders,Metabolic Syndrome,metabolic syndrome diagnosis,Monte Carlo cross-validation,Monte Carlo Cross-validation,Monte Carlo methods,noninvasive parameters,patient diagnosis,Standards}
}

@article{sun_concurrent_2014,
  title    = {Concurrent {{Average Memory Access Time}}},
  author   = {Sun, Xian-He and Wang, Dawei},
  year     = {2014},
  month    = may,
  journal  = {Computer},
  volume   = {47},
  number   = {5},
  pages    = {74--80},
  issn     = {1558-0814},
  doi      = {10.1109/MC.2013.227},
  urldate  = {2024-09-18},
  abstract = {Traditional memory performance metrics, such as average memory access time (AMAT), are designed for sequential data accesses and can prove misleading for contemporary cache technologies that increasingly rely on access concurrency. C-AMAT, a new performance metric, accounts for concurrency at both the component and system levels for modern memory design.},
  keywords = {advanced cache design measurement,AMAT,Benchmark testing,cache concurrency,Concurrent computing,high performance computing,memory concurrency,Memory management,memory metrics,memory performance measurement,Multicore processing,Performance evaluation}
}

@book{taylor_software_2009,
  title      = {Software {{Architecture}}: {{Foundations}}, {{Theory}}, and {{Practice}}},
  shorttitle = {Software {{Architecture}}},
  author     = {Taylor, R. N. and Medvidovic, N. and Dashofy, E. M.},
  year       = {2009},
  month      = jan,
  edition    = {1st edition},
  publisher  = {Wiley},
  address    = {Hoboken, N.J},
  abstract   = {Software architecture is foundational to the development of large, practical software-intensive applications. This brand-new text covers all facets of software architecture and how it serves as the intellectual centerpiece of software development and evolution. Critically, this text focuses on supporting creation of real implemented systems. Hence the text details not only modeling techniques, but design, implementation, deployment, and system adaptation -- as well as a host of other topics -- putting the elements in context and comparing and contrasting them with one another. Rather than focusing on one method, notation, tool, or process, this new text/reference widely surveys software architecture techniques, enabling the instructor and practitioner to choose the right tool for the job at hand. Software Architecture is intended for upper-division undergraduate and graduate courses in software architecture, software design, component-based software engineering, and distributed systems},
  isbn       = {978-0-470-16774-8},
  langid     = {english}
}

@incollection{villegas_chapter_2017,
  title     = {Chapter 2 - {{Architecting Software Systems}} for {{Runtime Self-Adaptation}}: {{Concepts}}, {{Models}}, and {{Challenges}}},
  booktitle = {Managing {{Trade-Offs}} in {{Adaptable Software Architectures}}},
  author    = {Villegas, N.M. and Tamura, G. and M{\"u}ller, H.A.},
  editor    = {Mistrik, Ivan and Ali, Nour and Kazman, Rick and Grundy, John and Schmerl, Bradley},
  year      = {2017},
  month     = jan,
  pages     = {17--43},
  publisher = {Morgan Kaufmann},
  address   = {Boston},
  doi       = {10.1016/B978-0-12-802855-1.00002-2},
  isbn      = {978-0-12-802855-1},
  keywords  = {Architecting for self-adaptation,Dynamic reconfiguration,Runtime adaptation,Self-adaptive software systems,Software adaptability,Software adaptation,Software self-adaptation}
}

@inproceedings{weyns_claims_2012,
  title     = {Claims and Supporting Evidence for Self-Adaptive Systems: {{A}} Literature Study},
  booktitle = {Proceedings of the 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
  author    = {Weyns, Danny and Iftikhar, M. Usman and Malek, Sam and Andersson, Jesper},
  date      = {2012},
  year      = {2012},
  series    = {{{SEAMS}} '12},
  pages     = {89--98},
  publisher = {IEEE Press},
  location  = {Zurich, Switzerland},
  address   = {Zurich, Switzerland},
  abstract  = {Despite the vast body of work on self-adaption, no systematic study has been performed on the claims associated with self-adaptation and the evidence that exists for these claims. As such an insight is crucial for researchers and engineers, we performed a literature study of the research results from SEAMS since 2006 and the associated Dagstuhl seminar in 2008. The study shows that the primary claims of self-adaptation are improved flexibility, reliability, and performance of the system. On the other hand, the tradeoffs implied by self-adaptation have not received much attention. Evidence is obtained from basic examples, or simply lacking. Few systematic empirical studies have been performed, and no industrial evidence is reported. From the study, we offer the following recommendations to move the field forward: to improve evaluation, researchers should make their assessment methods, tools and data publicly available; to deal with poor discussion of limitations, conferences/workshops should require an explicit section on limitations in engineering papers; to improve poor treatment of tradeoffs, this aspect should be an explicit subject of reviews; and finally, to enhance industrial validation, the best academy-industry efforts could be formally recognized by the community.},
  isbn      = {978-1-4673-1787-0},
  pagetotal = {10},
  keywords  = {Communities,Concrete,Context,Documentation,Software systems,Systematics}
}

@book{white_fluid_2002,
  title     = {Fluid {{Mechanics}} with {{Student Resources CD-ROM}}},
  author    = {White, Frank M.},
  year      = {2002},
  month     = dec,
  edition   = {5th Edition},
  publisher = {McGraw-Hill Science/Engineering/Math},
  address   = {Boston},
  abstract  = {The fifth edition of FLUID MECHANICS continues the tradition of precision, accuracy, accessibility and strong conceptual presentation. The author balances three separate approaches{\textquestiondown}integral, differential and experimental{\textquestiondown}to provide a foundation for fluid mechanics concepts and applications. Chapter 1 now provides a more student-accessible introduction to the field. After covering the basics in the first six chapters, the text moves on to applications, with chapters on ducts, immersed bodies, potential flow, compressible flow, open channel flow and turbomachinery. New material on CFD is included in Chapter 7 to give students a sense of its importance in modern engineering practice. The fifth edition includes a new problem-solving methodology, introduced at the beginning of the book and used consistently in worked-out examples. 1,650 chapter problems are now included, organized into several problem types. Students can progress from general ones to those involving design, multiple steps and computer usage. Word problems are included to build readers' conceptual understanding of the subject, and FE Exam problems (in multiple-choice format) are included. EES (Engineering Equation Solver) software is included so that students can effectively use the computer to model, solve and modify typical fluid mechanics problems. A CD ROM containing EES is free with every book, and Appendix E describes its use and application to fluid mechanics. A limited version of EES, that does not expire, is included on the CD ROM; users of the book can also download and distribute the full Academic Version of EES, which is renewed annually with a new username and password. In addition to the bound-in CD ROM, a full Book Website is available for students and instructors. This contains an electronic Student Study Guide; interactive FE Exam questions; links to professional websites; PowerPoint slides of book figures; and a link to the EES website. A printed Solutions Manual is also available to adopters of the fifth edition.},
  isbn      = {978-0-07-283180-1},
  langid    = {english}
}

@article{wohlin_guidelines_2020,
  title    = {Guidelines for the Search Strategy to Update Systematic Literature Reviews in Software Engineering},
  author   = {Wohlin, Claes and Mendes, Emilia and Felizardo, Katia Romero and Kalinowski, Marcos},
  year     = {2020},
  month    = nov,
  journal  = {Information and Software Technology},
  volume   = {127},
  pages    = {106366},
  issn     = {0950-5849},
  doi      = {10.1016/j.infsof.2020.106366},
  urldate  = {2023-02-20},
  abstract = {Context Systematic Literature Reviews (SLRs) have been adopted within Software Engineering (SE) for more than a decade to provide meaningful summaries of evidence on several topics. Many of these SLRs are now potentially not fully up-to-date, and there are no standard proposals on how to update SLRs in SE. Objective The objective of this paper is to propose guidelines on how to best search for evidence when updating SLRs in SE, and to evaluate these guidelines using an SLR that was not employed during the formulation of the guidelines. Method To propose our guidelines, we compare and discuss outcomes from applying different search strategies to identify primary studies in a published SLR, an SLR update, and two replications in the area of effort estimation. These guidelines are then evaluated using an SLR in the area of software ecosystems, its update and a replication. Results The use of a single iteration forward snowballing with Google Scholar, and employing as a seed set the original SLR and its primary studies is the most cost-effective way to search for new evidence when updating SLRs. Furthermore, the importance of having more than one researcher involved in the selection of papers when applying the inclusion and exclusion criteria is highlighted through the results. Conclusions Our proposed guidelines formulated based upon an effort estimation SLR, its update and two replications, were supported when using an SLR in the area of software ecosystems, its update and a replication. Therefore, we put forward that our guidelines ought to be adopted for updating SLRs in SE.},
  langid   = {english},
  keywords = {Searching for evidence,Snowballing,Software engineering,Systematic literature review update,Systematic literature reviews}
}

@article{wong_self-adaptive_2022,
  title        = {Self-Adaptive Systems: {{A}} Systematic Literature Review across Categories and Domains},
  shorttitle   = {Self-Adaptive Systems},
  author       = {Wong, Terence and Wagner, Markus and Treude, Christoph},
  year         = {2022},
  date         = {2022-08-01},
  journaltitle = {Information and Software Technology},
  shortjournal = {Information and Software Technology},
  journal      = {Information and Software Technology},
  volume       = {148},
  pages        = {106934},
  issn         = {0950-5849},
  doi          = {10.1016/j.infsof.2022.106934},
  url          = {https://www.sciencedirect.com/science/article/pii/S0950584922000854},
  urldate      = {2023-02-27},
  abstract     = {Context: Championed by IBM’s vision of autonomic computing paper in 2003, the autonomic computing research field has seen increased research activity over the last 20 years. Several conferences (SEAMS, SASO, ICAC) and workshops (SISSY) have been established and have contributed to the autonomic computing knowledge base in search of a new kind of system -- a self-adaptive system (SAS). These systems are characterized by being context-aware and can act on that awareness. The actions carried out could be on the system or on the context (or environment). The underlying goal of a SAS is the sustained achievement of its goals despite changes in its environment. Objective: Despite a number of literature reviews on specific aspects of SASs ranging from their requirements to quality attributes, we lack a systematic understanding of the current state of the art. Method: This paper contributes a systematic literature review into self-adaptive systems using the dblp computer science bibliography as a database. We filtered the records systematically in successive steps to arrive at 293 relevant papers. Each paper was critically analyzed and categorized into an attribute matrix. This matrix consisted of five categories, with each category having multiple attributes. The attributes of each paper, along with the summary of its contents formed the basis of the literature review that spanned 30 years (1990–2020). Results: We characterize the maturation process of the research area from theoretical papers over practical implementations to more holistic and generic approaches, frameworks, and exemplars, applied to areas such as networking, web services, and robotics, with much of the recent work focusing on IoT and IaaS. Conclusion: While there is an ebb and flow of application domains, domains like bio-inspired approaches, security, and cyber–physical systems showed promise to grow heading into the 2020s.},
  langid       = {english},
  keywords     = {Literature review,Self-adaptive systems}
}

@article{yang_designing_2010,
  title    = {Designing an Effective {{P2P}} System for a {{VoD}} System to Exploit the Multicast Communication},
  author   = {Yang, X.Y. and Cores, F. and Hern{\'a}ndez, P. and Ripoll, A. and Luque, E.},
  year     = {2010},
  month    = dec,
  journal  = {Journal of Parallel and Distributed Computing},
  volume   = {70},
  number   = {12},
  pages    = {1175--1192},
  issn     = {0743-7315},
  doi      = {10.1016/j.jpdc.2010.07.007},
  abstract = {A distributed video-on-demand system~(DVoD) with multiple server-nodes is a cost-effective and fault-tolerant solution for a high scalable enterprise video-on-demand (VoD) system. However, such a server-oriented design is highly vulnerable to workload variations given that the service capacity is limited. Peer-to-Peer (P2P) has been introduced as an architectural solution with self-growing capacity. However, the characteristics of a pure P2P system such as the peer transient nature and high network overhead make this kind of architecture unsuitable for a fully interactive VoD system. In this paper, we propose a new efficient integrated VoD architecture, called DPn2Pm, that combines DVoD with a P2P system and multicast communications. The DVoD's server-nodes provide a minimum required quality of service (QoS) and the P2P system is able to offer the mechanism to increase the system service capacity according to client demands. Multicast communication, wherever it is possible, is effectively exploited by our P2P system. In our design, each client is able to send video information to a set of m clients using only one multicast channel. Furthermore, the collaboration mechanism is able to coordinate a set of clients to create one collaboration group to replace the server, providing an extensive, efficient and low network-overhead collaboration mechanism from n-peers to m-peers. Regardless of the video the client is watching, our P2P scheme allows every active client to collaborate with the server. The P2P scheme is complemented with recovery mechanisms that are able to replace the failed client before affecting the QoS, offering continuous playback. The proposed approach has been broadly evaluated, firstly using a mathematical model to derive the theoretical performance and secondly using a simulation environment to analyze the system's dynamic behavior, the VCR interaction impact and the client failures. Comparing DPn2Pm with other DVoD architectures and the most relevant P2P delivery policies, we show that our design is an improvement on previous solutions, providing a higher scalability.},
  keywords = {Content delivery network,Distributed VoD,Multicast,P2P,Proxy,Video-on-demand}
}

@article{yang_meaningful_2022,
  title        = {Meaningful {{Update}} and {{Repair}} of {{Markov Decision Processes}} for {{Self-Adaptive Systems}}},
  author       = {Yang, Wen-Hua and Pan, Min-Xue and Zhou, Yu and Huang, Zhi-Qiu},
  date         = {2022-02-01},
  year         = {2022},
  journal      = {Journal of Computer Science and Technology},
  journaltitle = {Journal of Computer Science and Technology},
  shortjournal = {Journal of Computer Science and Technology},
  volume       = {37},
  number       = {1},
  pages        = {106--127},
  issn         = {1860-4749},
  doi          = {10.1007/s11390-021-1484-8},
  url          = {https://doi.org/10.1007/s11390-021-1484-8},
  abstract     = {Self-adaptive systems are able to adjust their behaviour in response to environmental condition changes and are widely deployed as Internetwares. Considered as a promising way to handle the ever-growing complexity of software systems, they have seen an increasing level of interest and are covering a variety of applications, e.g., autonomous car systems and adaptive network systems. Many approaches for the construction of self-adaptive systems have been developed, and probabilistic models, such as Markov decision processes (MDPs), are one of the favoured. However, the majority of them do not deal with the problems of the underlying MDP being obsolete under new environments or unsatisfactory to the given properties. This results in the generated policies from such MDP failing to guide the self-adaptive system to run correctly and meet goals. In this article, we propose a systematic approach to updating an obsolete MDP by exploring new states and transitions and removing obsolete ones, and repairing an unsatisfactory MDP by adjusting its structure in a more meaningful way rather than arbitrarily changing the transition probabilities to values not in line with reality. Experimental results show that the MDPs updated and repaired by our approach are more competent in guiding the self-adaptive systems’ correct running compared with the original ones.},
  keywords     = {Markov decision process,model repair,self-adaptive system},
}


@inproceedings{yang_systematic_2014,
  title     = {A Systematic Literature Review of Requirements Modeling and Analysis for Self-Adaptive Systems},
  booktitle = {Requirements Engineering: {{Foundation}} for Software Quality},
  author    = {Yang, Zhuoqun and Li, Zhi and Jin, Zhi and Chen, Yunchuan},
  year      = {2014},
  date      = {2014},
  pages     = {55--71},
  publisher = {Springer International Publishing},
  address   = {Cham},
  location  = {Cham},
  abstract  = {[Context and motivation] Over the last decade, researchers and engineers have developed a vast body of methodologies and technologies in requirements engineering for self-adaptive systems. Although existing studies have explored various aspects of this topic, few of them have categorized and evaluated these areas of research in requirements modeling and analysis. [Question/Problem] This review aims to investigate what modeling methods, RE activities, requirements quality attributes, application domains and research topics have been studied and how well these studies have been conveyed. [Principal ideas/results] We conduct a systematic literature review to answer the research questions by searching relevant studies, appraising the quality of these studies and extracting available data. The results are derived by synthesizing the extracted data with statistical methods. [Contributions] This paper provides an updated review of the research literature, enabling researchers and practitioners to better understand the research trends in these areas and identify research gaps which need to be further studied.},
  isbn      = {978-3-319-05843-6}
}

@inproceedings{zhang_application_2016,
  title     = {Application of Complexity and Brittleness on Software Architecture},
  booktitle = {2016 8th {{IEEE International Conference}} on {{Communication Software}} and {{Networks}} ({{ICCSN}})},
  author    = {Zhang, Hong and Hu, Changzhen and Wang, Xiaojun},
  year      = {2016},
  month     = jun,
  publisher = {IEEE},
  location  = {Beijing, China},
  address   = {Beijing, China},  
  pages     = {570--573},
  doi       = {10.1109/ICCSN.2016.7586587},
  abstract  = {Just like the catastrophe in power grid, software system may collapse during its operation. It reflects the complexity in software system itself, and the brittleness of software system is the main reason which results in the collapse. The notion of complex system and brittleness is introduced into the study of software system and some aspects which can induce the system to collapse are also discussed. Specifically, the notions of complex system, complex network and brittleness are introduced at first, then a detailed description of the complexity of software system is given; following that a fast-slow alternative dynamic model is built, which consists of a slow-dynamic model and a fast-dynamic model. In the end, a complex theory framework of brittleness on software architecture is presented, which covers the brittleness of software architecture from the way of language description, the analytical method, modeling to the evaluation. This can give a comprehensive research platform on the brittleness of software system. Some main research areas are also given for future study.},
  keywords  = {brittleness analysis,complex network,Complex networks,complex system,Complex systems,Complexity theory,Power system faults,software architecture,Software architecture,software security,Software systems,Topology}
}
